{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91c6ce51-6690-44fc-8ca3-9bdc83b22d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gzip\n",
    "import struct\n",
    "from array import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b40f090-f138-4a9d-b867-97b1bf8e35e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '../dataset/test'  \n",
    "image_size = (32, 32)\n",
    "class_descriptions = [\n",
    "        \"cheetah\", \"deer\", \"giraffe\", \"hyena\", \"jaguar\",\n",
    "        \"leopard\", \"tapir\", \"tiger\", \"WhaleShark\", \"zebra\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde5d65a-b932-4f37-9d08-88ebbfe3f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folders(base_folder, class_descriptions, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, class_name in enumerate(class_descriptions):\n",
    "        folder_path = os.path.join(base_folder, class_name)\n",
    "        print(\"Processing class: \", class_name)\n",
    "        if not os.path.exists(folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                img = Image.open(os.path.join(folder_path, filename)).convert('L')  # Convert image to grayscale\n",
    "                img = img.resize(image_size)  # Resize image to 32x32 pixels\n",
    "                img_np = np.array(img, dtype=np.uint8)\n",
    "                images.append(img_np)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59bfa330-45ab-41e7-9420-c829c67b5fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class:  cheetah\n",
      "Processing class:  deer\n",
      "Processing class:  giraffe\n",
      "Processing class:  hyena\n",
      "Processing class:  jaguar\n",
      "Processing class:  leopard\n",
      "Processing class:  tapir\n",
      "Processing class:  tiger\n",
      "Processing class:  WhaleShark\n",
      "Processing class:  zebra\n"
     ]
    }
   ],
   "source": [
    "images, labels = load_images_from_folders(base_folder, class_descriptions, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e61bf0c3-3f27-4e9a-b735-08aef5b0e40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32) (40000,)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61919fa7-8453-4312-b366-e9c36e59d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_idx_images(filepath, images):\n",
    "    if not isinstance(images, (np.ndarray, list)):\n",
    "        raise TypeError('Unsupported data type.')\n",
    "\n",
    "    # Ensure images is a numpy array\n",
    "    images = np.array(images)\n",
    "\n",
    "    # Ensure the images array has the right shape\n",
    "    if images.ndim != 3:\n",
    "        raise ValueError('Images array must be 3-dimensional.')\n",
    "\n",
    "    magic_number = 2051\n",
    "    num_images = images.shape[0]\n",
    "    rows = images.shape[1]\n",
    "    cols = images.shape[2]\n",
    "\n",
    "    header = struct.pack(\">IIII\", magic_number, num_images, rows, cols)\n",
    "    \n",
    "    data_list = [header]\n",
    "    for image in images:\n",
    "        data_list.append(struct.pack('>' + 'B' * rows * cols, *image.flatten()))\n",
    "\n",
    "    data = b''.join(data_list)\n",
    "\n",
    "    with gzip.open(filepath, 'wb') as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82072dca-6632-4363-ace1-8e2947f6c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_idx_images('../dataset/test-images-idx3-ubyte.gz', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de2ec289-ed60-4e3c-961d-5597aa11aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_idx_labels(filepath, labels):\n",
    "    if not isinstance(labels, (np.ndarray, list)):\n",
    "        raise TypeError('Unsupported label type.')\n",
    "\n",
    "    # Ensure labels is a numpy array\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Ensure the labels array has the right shape\n",
    "    if labels.ndim != 1:\n",
    "        raise ValueError('Labels array must be 1-dimensional.')\n",
    "\n",
    "    magic_number = 2049\n",
    "    num_labels = len(labels)\n",
    "\n",
    "    data = struct.pack(\">II\", magic_number, num_labels)\n",
    "    \n",
    "    data += struct.pack('>' + 'B' * num_labels, *labels)\n",
    "\n",
    "    with gzip.open(filepath, 'wb') as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee749b10-ee21-4bff-b8ed-d3a47df6d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_idx_labels('../dataset/test-labels-idx1-ubyte.gz', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf57d1a-aa6a-487b-a9a5-f1f6c49c0d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2094cf78-47da-41cc-9089-8731a628521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path_img, path_lbl):\n",
    "    \n",
    "    with gzip.open(path_lbl, 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8))\n",
    "        if magic != 2049:\n",
    "            raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "\n",
    "        labels = array(\"B\", file.read())\n",
    "\n",
    "    with gzip.open(path_img, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "\n",
    "        image_data = array(\"B\", file.read())\n",
    "\n",
    "    images = np.zeros((size, rows, cols), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(size):\n",
    "        images[i] = np.array(image_data[i * rows * cols:(i + 1) * rows * cols]).reshape(rows, cols)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f22c9905-e924-4694-b5ef-949017addbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = load('../dataset/test-images-idx3-ubyte.gz', '../dataset/test-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56821043-9145-4942-a113-644ad57f142a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 32, 32),\n",
       " (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       "  array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000],\n",
       "        dtype=int64)))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_images).shape, np.unique(np.array(test_labels), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e734376-7fbf-4085-a9ff-a4a954a852c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c142e219-16d3-45ad-8a87-932383cc0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from spots_10_loader import SPOT10Loader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8ef4d94-26a8-4a9e-b400-52d053a22800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([4000, 4000, 4000, 4000, 4000, 4000, 4000, 4000, 4000, 4000],\n",
      "      dtype=int64))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000],\n",
      "      dtype=int64))\n",
      "(40000, 32, 32) (40000,)\n",
      "(10000, 32, 32) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_train, y_train = SPOT10Loader.get_data(dataset_dir=\"../dataset\", kind=\"train\")\n",
    "X_test, y_test = SPOT10Loader.get_data(dataset_dir=\"../dataset\", kind=\"test\")\n",
    "\n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True))\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the data to include the channel dimension\n",
    "#X_train = tf.expand_dims(X_train, axis=-1)\n",
    "#X_test = tf.expand_dims(X_test, axis=-1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 32, 32, 1)\n",
    "X_test = X_test.reshape(-1, 32, 32, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e7c8b7f-8569-4267-86f5-585a54461728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 32, 32, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb809b96-97b7-4f12-883a-be9854f67036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52998be2-3b93-4179-a547-17a1bf9554d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37a22c80-a976-4d2f-8577-335da8d5f350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.4261 - accuracy: 0.8457 - val_loss: 0.4787 - val_accuracy: 0.8262\n",
      "Epoch 2/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.4074 - accuracy: 0.8507 - val_loss: 0.4701 - val_accuracy: 0.8268\n",
      "Epoch 3/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3782 - accuracy: 0.8626 - val_loss: 0.5153 - val_accuracy: 0.8220\n",
      "Epoch 4/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3607 - accuracy: 0.8700 - val_loss: 0.4911 - val_accuracy: 0.8267\n",
      "Epoch 5/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3456 - accuracy: 0.8744 - val_loss: 0.5091 - val_accuracy: 0.8213\n",
      "Epoch 6/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3215 - accuracy: 0.8806 - val_loss: 0.5895 - val_accuracy: 0.8074\n",
      "Epoch 7/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3027 - accuracy: 0.8882 - val_loss: 0.5012 - val_accuracy: 0.8287\n",
      "Epoch 8/200\n",
      "625/625 [==============================] - 3s 6ms/step - loss: 0.2870 - accuracy: 0.8934 - val_loss: 0.5698 - val_accuracy: 0.8206\n",
      "Epoch 9/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2679 - accuracy: 0.8999 - val_loss: 0.5397 - val_accuracy: 0.8342\n",
      "Epoch 10/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2499 - accuracy: 0.9082 - val_loss: 0.5583 - val_accuracy: 0.8313\n",
      "Epoch 11/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2405 - accuracy: 0.9116 - val_loss: 0.5808 - val_accuracy: 0.8280\n",
      "Epoch 12/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2170 - accuracy: 0.9187 - val_loss: 0.5842 - val_accuracy: 0.8342\n",
      "Epoch 13/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2108 - accuracy: 0.9217 - val_loss: 0.6210 - val_accuracy: 0.8224\n",
      "Epoch 14/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9280 - val_loss: 0.6356 - val_accuracy: 0.8286\n",
      "Epoch 15/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1906 - accuracy: 0.9282 - val_loss: 0.6652 - val_accuracy: 0.8283\n",
      "Epoch 16/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1729 - accuracy: 0.9353 - val_loss: 0.6883 - val_accuracy: 0.8271\n",
      "Epoch 17/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1701 - accuracy: 0.9363 - val_loss: 0.7559 - val_accuracy: 0.8206\n",
      "Epoch 18/200\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1550 - accuracy: 0.9418 - val_loss: 0.7959 - val_accuracy: 0.8132\n",
      "Epoch 19/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1523 - accuracy: 0.9437 - val_loss: 0.7812 - val_accuracy: 0.8219\n",
      "Epoch 20/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1440 - accuracy: 0.9469 - val_loss: 0.8183 - val_accuracy: 0.8264\n",
      "Epoch 21/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1346 - accuracy: 0.9502 - val_loss: 0.8261 - val_accuracy: 0.8245\n",
      "Epoch 22/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1426 - accuracy: 0.9471 - val_loss: 0.8914 - val_accuracy: 0.8169\n",
      "Epoch 23/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1174 - accuracy: 0.9556 - val_loss: 0.9039 - val_accuracy: 0.8264\n",
      "Epoch 24/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1184 - accuracy: 0.9566 - val_loss: 0.9410 - val_accuracy: 0.8179\n",
      "Epoch 25/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1191 - accuracy: 0.9556 - val_loss: 0.9376 - val_accuracy: 0.8284\n",
      "Epoch 26/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1094 - accuracy: 0.9604 - val_loss: 1.0457 - val_accuracy: 0.8107\n",
      "Epoch 27/200\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1088 - accuracy: 0.9599 - val_loss: 1.0249 - val_accuracy: 0.8203\n",
      "Epoch 28/200\n",
      "425/625 [===================>..........] - ETA: 0s - loss: 0.1162 - accuracy: 0.9587"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\.conda\\envs\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.conda\\envs\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\.conda\\envs\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\.conda\\envs\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "186a78cd-031d-4b05-807a-75c2f8eee6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5040 - accuracy: 0.8078\n",
      "Test accuracy: 0.8077999949455261\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb76c2-262a-4cf0-ab2f-d560e076cb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8063ff52-14f0-4a84-b320-bb1c0fbf0c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Predict the classes for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Convert predictions from one-hot encoded to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "# Convert test labels from one-hot encoded to class labels\n",
    "y_true = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "433562fe-5b73-4bd8-a0ca-c8b837e4332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e39289e4-8f7b-4201-a336-da767aadc6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[780,   2,   8,  94,  63,  41,   1,   9,   2,   0],\n",
       "       [  1, 765,   5,  10,   0,   0,  73,   6, 138,   2],\n",
       "       [  5,  17, 842,  84,  12,  21,   7,  11,   1,   0],\n",
       "       [ 68,   9,   5, 859,  20,   0,   1,  38,   0,   0],\n",
       "       [ 76,   1,  24,  38, 752,  87,   3,  18,   0,   1],\n",
       "       [169,   1,  30,  46, 349, 398,   0,   1,   6,   0],\n",
       "       [  0,  95,   5,   0,   2,   0, 865,   5,  11,  17],\n",
       "       [  0,   5,   0,  15,   4,   0,   3, 924,   0,  49],\n",
       "       [  2,  47,   1,   0,   0,   1,   7,   0, 942,   0],\n",
       "       [  1,   0,   0,   0,   3,   0,  11,  33,   1, 951]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa53d4a4-cc18-45f0-9457-0067b02720e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e7c23-66c2-419c-90d5-e6ddc4def88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312d4ff-d173-4612-8bbd-edd8e7603816",
   "metadata": {},
   "outputs": [],
   "source": [
    "'../dataset/test-images-idx3-ubyte.gz'\n",
    "'../dataset/test-labels-idx1-ubyte.gz'\n",
    "\n",
    "'../dataset/train-images-idx3-ubyte.gz'\n",
    "'../dataset/train-labels-idx1-ubyte.gz'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
