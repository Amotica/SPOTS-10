{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a3efd36-c79a-4d35-992e-3401b8ea868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, applications, models\n",
    "import numpy as np\n",
    "from utilities.distiller import Distiller\n",
    "from utilities.spots_10_loader import SPOT10Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1870eb4-108d-4157-ac79-2032c2053a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_teacher_model(model_name=\"MobileNet\", input_shape=(32, 32, 3), num_classes=10):\n",
    "    base_model = getattr(applications, model_name)(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "\n",
    "    teacher = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    return teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b3d859-89f1-4d58-9147-16d6b3269fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_student_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "    student = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes),\n",
    "    ], name=\"student\")\n",
    "\n",
    "    return student\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed940a24-869e-407c-ac80-07e55346bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_dir=\"dataset\", kind=\"train\", input_shape=(32, 32, 3)):\n",
    "    x_data, y_label = SPOT10Loader.get_data(dataset_dir=dataset_dir, kind=kind)\n",
    "\n",
    "    x_data = x_data.astype('float32') / 255.0\n",
    "    x_data = np.expand_dims(x_data, axis=-1)\n",
    "    y_label = np.expand_dims(y_label, axis=-1)\n",
    "    x_data = np.repeat(x_data, 3, axis=-1)\n",
    "\n",
    "    return x_data, y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4bc0ee6-09ac-4889-a0f7-bbd2e3b3944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_data(dataset_dir=\"dataset\", kind=\"train\", input_shape=(32, 32, 3))\n",
    "x_test, y_test = load_data(dataset_dir=\"dataset\", kind=\"test\", input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd6cf2a-5b5e-4292-aec8-30f30a19c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"MobileNet\", \"ResNet50\", \"MobileNetV2\", \"DenseNet121\", \"NASNetMobile\", \n",
    "teacher_names=[\"EfficientNetB0\", \"EfficientNetB1\", \"EfficientNetB2\", \"EfficientNetB3\", \"ConvNeXtTiny\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "335dc55a-bbe1-4acf-bc25-e74ce6c549ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training benchmark model:  EfficientNetB0 ...\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - ETA: 0s - sparse_categorical_accuracy: 0.4860\n",
      "Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.62080, saving model to EfficientNetB0_best_model\n",
      "INFO:tensorflow:Assets written to: EfficientNetB0_best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: EfficientNetB0_best_model\\assets\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Define the ModelCheckpoint callback\u001b[39;00m\n\u001b[0;32m     26\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     27\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mteacher_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_best_model\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Path to save the model, SavedModel format by default\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_sparse_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Monitor the validation accuracy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Save in TensorFlow SavedModel format\u001b[39;00m\n\u001b[0;32m     33\u001b[0m )\n\u001b[1;32m---> 35\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mdistiller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.conda\\envs\\wellcome\\lib\\json\\encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32m~\\.conda\\envs\\wellcome\\lib\\json\\encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[0;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
     ]
    }
   ],
   "source": [
    "for teacher_name in teacher_names:\n",
    "    print(\"Training benchmark model: \", teacher_name, \"...\")\n",
    "    teacher = create_teacher_model(model_name=teacher_name)\n",
    "    student = create_student_model()\n",
    "    \n",
    "    distiller = Distiller(student=student, teacher=teacher)\n",
    "    distiller.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "        student_loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
    "        alpha=0.1,\n",
    "        temperature=10,\n",
    "    )\n",
    "    \n",
    "    # Define the ReduceLROnPlateau callback\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_sparse_categorical_accuracy',  # Monitor the student loss\n",
    "        factor=0.5,              # Reduce learning rate by a factor of 0.5\n",
    "        patience=5,              # Number of epochs with no improvement after which learning rate will be reduced\n",
    "        min_lr=1e-6,             # Lower bound on the learning rate\n",
    "        verbose=1                # Output reduction process\n",
    "    )\n",
    "    \n",
    "    # Define the ModelCheckpoint callback\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=teacher_name + '_best_model',  # Path to save the model, SavedModel format by default\n",
    "        monitor='val_sparse_categorical_accuracy',  # Monitor the validation accuracy\n",
    "        save_best_only=True,  # Save only the best model\n",
    "        mode='max',  # Mode for the monitored metric, 'max' for accuracy\n",
    "        verbose=1,  # Output saving process\n",
    "        save_format='tf'  # Save in TensorFlow SavedModel format\n",
    "    )\n",
    "\n",
    "    history = distiller.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test),  callbacks=[reduce_lr, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f384848-6883-4d07-8698-bac62b19b3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce48a5a-7c3e-423a-b1d9-9eb6fb39ddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 0.7087\n"
     ]
    }
   ],
   "source": [
    "teacher_names=[\"MobileNet\", \"ResNet50\", \"MobileNetV2\",\n",
    "                        \"DenseNet121\", \"NASNetMobile\", \"EfficientNetB0\",\n",
    "                        \"EfficientNetB1\", \"EfficientNetB2\", \"EfficientNetB3\", \"ConvNeXtTiny\"]\n",
    "\n",
    "columns = ['model_name', 'accuracy']\n",
    "df = pd.DataFrame(columns=self.columns)\n",
    "\n",
    "for teacher_name in teacher_names:\n",
    "    # Load the saved model\n",
    "    saved_model_path = teacher_name+'_best_model'  # Path to the directory containing the saved model\n",
    "    \n",
    "    # Load the model\n",
    "    model = tf.keras.models.load_model(saved_model_path)\n",
    "    test_accuracy = model.evaluate(x_test, y_test)\n",
    "    \n",
    "    ## Save results to DataFrame\n",
    "    new_data = pd.DataFrame({'model_name': [teacher_name], 'accuracy': [accuracy]})\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6124e6-2c7e-46de-aa1d-bba1a9f3aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the destination folder for the benchmark results is not exist\n",
    "save_directory = \"benchmark_results\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "csv_file = save_directory + \"/benchmark_accuracies.csv\"\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"Test Accuracy results saved to {self.csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2714988-3728-4f10-92a5-f8ab76b3a1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.5839\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = distiller.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "907fc51c-32f5-421b-aea6-f578c13acea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.583899974822998"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33386d0f-9e17-4bce-a451-85ed249520de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "teacher_names=[\"MobileNet\", \"ResNet50\", \"MobileNetV2\",\n",
    "                        \"DenseNet121\", \"NASNetMobile\", \"EfficientNetB0\",\n",
    "                        \"EfficientNetB1\", \"EfficientNetB2\", \"EfficientNetB3\", \"ConvNeXtTiny\"]\n",
    "\n",
    "columns = ['model_name', 'accuracy', 'loss']\n",
    "df = pd.DataFrame(columns=self.columns)\n",
    "\n",
    "for teacher_name in teacher_names:\n",
    "    Print(\"Training benchmark model: \", teacher_name, \"...\")\n",
    "    teacher = create_teacher_model(model_name=teacher_name)\n",
    "    student = create_student_model()\n",
    "    \n",
    "    distiller = Distiller(student=student, teacher=teacher)\n",
    "    distiller.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "        student_loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
    "        alpha=0.1,\n",
    "        temperature=10,\n",
    "    )\n",
    "    \n",
    "    distiller.fit(x_train, y_train, epochs=3)\n",
    "    distiller.evaluate(x_test, y_test)\n",
    "    \n",
    "    ## Save results to DataFrame\n",
    "    new_data = pd.DataFrame({'model_name': [teacher_name], 'accuracy': [accuracy], 'loss': [loss]})\n",
    "    df = pd.concat([df, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187e2db-62e5-4069-9a51-9b8121596a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "self.df.to_csv(self.csv_file, index=False)\n",
    "print(f\"Test Accuracy results saved to {self.csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff26555a-310a-4e35-9480-377f5c357c51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distiller' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mdistiller\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'distiller' is not defined"
     ]
    }
   ],
   "source": [
    "acc = distiller.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d1dcb-fcb1-4589-9118-698bbc5f8e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
